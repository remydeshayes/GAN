# Deep Learning projet @ ENSAE
## DCGAN and cycleGAN

RÃ©my DESHAYES, Maxime BERILLON

When studying an unsupervised learning problem, data at hand supposedly follow a distribution that we want to discover and learn. 

Our report follows 4 steps. First, section 1 introduces two approaches to tackle the problem of probability distribution learning and make a brief introduction to a model - the GAN - that leverages one of these approaches. Then, section 2 builds on the remarks made in the previous part and introduces the Wasserstein GAN. Section 3 and section 4 propose an in-depth review of two GANs and their implementations, namely the DCGAN and the CycleGAN. 

Implementations can be found here or on Google Colab [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1yq2O7Ym5EndvLYROp0u5V3XmGTIwRNQC?usp=sharing)

![alt text](https://miro.medium.com/max/2424/1*FL6DWzN-awxCaG8bS1ZD_Q.png)
